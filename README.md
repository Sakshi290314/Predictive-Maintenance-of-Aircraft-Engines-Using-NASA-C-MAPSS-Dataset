**Predictive Maintenance on NASA C-MAPSS Engine Dataset**

ğŸ”§ Predicting aircraft engine failures before they happen â€” using NASA's real-world turbofan sensor data and ensemble machine learning models (Random Forest, XGBoost, LightGBM) to estimate Remaining Useful Life (RUL) and trigger advance maintenance warnings.

**Project workflow**

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Project Pipeline                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   ğŸ“Š RAW DATA                  ğŸ”§ PREPROCESSING            ğŸ¤– ML MODELS
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   NASA C-MAPSS          â†’      Clean & Transform      â†’     Train 3 Models
   Dataset                      Drop constant sensors        Random Forest
   100 Engines                  Normalize (MinMaxScaler)     XGBoost
   21 Sensors                   Create RUL column            LightGBM
   20,631 Records               Clip RUL at 125 cycles
                                                                  â†“

   ğŸ“ˆ EVALUATION                  ğŸ† BEST MODEL               ğŸ’¾ OUTPUT
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   RMSE Comparison       â†’     Best ML Model          â†’     Predict RUL
   RÂ² Score                    Cross Validation             Early Warning
   Residual Plots               Feature Importance           Save Model
   Model Comparison             Confusion Matrix             joblib/pickle

**About the Dataset**

This project uses the FD001 subset â€” one operating condition (Sea Level) and one fault type (HPC Degradation), making it the cleanest and most focused subset for building and evaluating machine learning models.

**Dataset  :** FD001
**Engines  :**100 (Training) + 100 (Testing)
**Condition: **ONE â€” Sea Level
**Fault    : **ONE â€” HPC (High Pressure Compressor) Degradation
**Records  : **20,631 total sensor readings

**Understanding the Data**

Think of 100 aircraft engines, each running continuously until it breaks down. Throughout their operation, 21 sensors attached to each engine constantly measure things like temperature, pressure, fan speed, and fuel flow. 

Each row in the dataset represents one engine at one point in time:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Engine ID â”‚ Cycle â”‚  3 Op. Settings  â”‚     21 Sensor Readings       â”‚
â”‚           â”‚       â”‚ (Operating Mode) â”‚ (Temp, Pressure, Speed...)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      1          1       [3 values]              [21 values]
      1          2       [3 values]              [21 values]
     ...        ...          ...                     ...
      1         192      [3 values]              [21 values]  â† Fails here

100 engines Ã— ~200 cycles each = 20,631 total records

**what We Are Predicting**

The goal is to predict the Remaining Useful Life (RUL) â€” how many operational cycles an engine has left before it fails.

**Engine Life Timeline:**

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Cycle 0                                      Cycle 192
(Brand New)          Running â†’               (Failure)

RUL at any point = Cycles remaining until failure
Cycle 50  â†’ RUL = 142  âœ… Engine is healthy
Cycle 120 â†’ RUL = 72   ğŸŸ¡ Monitor closely  
Cycle 170 â†’ RUL = 22   ğŸŸ  Schedule maintenance
Cycle 190 â†’ RUL = 2    ğŸ”´ Critical â€” replace immediately!

**Phase 1 â€” Data Exploration**
Before building any model, the raw sensor data was explored to understand how engine health changes over time and which sensors show meaningful degradation patterns.

**What Was Done**
The training file was loaded with proper column names, empty columns were removed, and basic structural checks were performed to confirm data quality.

**Key Output â€” Engine Lifecycle Check**
Number of unique engines  : 100
Total measurements        : 20,631
Engine 1 lifecycle        : 192 cycles before failure

**Sensor Degradation Plot**
The plot below shows sensor readings for 4 different engines over their full lifetime. Each line represents one sensor tracked from the first cycle until engine failure.


Shows how sensor readings change as engines approach failure. Clear degradation patterns visible.

**Phase 2 â€” Data Preprocessing**
Step 1 â€” Load Raw Data
Loaded train_FD001.txt with proper column names and removed empty columns caused by trailing spaces.

Step 2 â€” Calculate RUL
Created the target variable that the model will predict.
RUL = Max Cycle of Engine âˆ’ Current Cycle
Engine 1 at Cycle 50 â†’ RUL = 192 - 50 = 142 cycles left

Step 3 â€” Remove Useless Sensors
Sensors that never change were dropped since they add no value to the model.
Removed : sensor_1, sensor_5, sensor_6, sensor_10, sensor_16, sensor_18, sensor_19
Kept    : 14 sensors out of 21

Step 4 â€” Correlation Analysis
Checked how strongly each remaining sensor relates to RUL. The graph above shows sensors with strong positive or negative correlation â€” these are the most important features for predicting engine failure.

Step 5 â€” Normalize Features
All 14 sensors + 3 operational settings were scaled to 0â€“1 range using MinMaxScaler so no feature dominates due to its measurement unit.

**Models Overview (Simple Explanation)
Machine Learning Models (Traditional Approach)**
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Random Forest                                           â”‚
â”‚     Think: 100 decision trees voting together               â”‚
â”‚     Result: RMSE = 41.37 cycles                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. XGBoost                                                 â”‚
â”‚     Think: Smart sequential tree building                   â”‚
â”‚     Result: RMSE = 42.11 cycles                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. LightGBM                                                â”‚
â”‚     Think: Faster version of XGBoost                        â”‚
â”‚     Result: RMSE = 41.18 cycles (Best ML Model)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**Hyperparameter Tuning (Making Models Better)**
